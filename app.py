import streamlit as st
import spacy
import nltk
import pandas as pd
import plotly.express as px
from collections import Counter
import re

# Download required NLTK data
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

try:
    nltk.data.find('taggers/averaged_perceptron_tagger')
except LookupError:
    nltk.download('averaged_perceptron_tagger')

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

# Load SpaCy model
@st.cache_resource
def load_spacy_model():
    try:
        return spacy.load("en_core_web_sm")
    except OSError:
        st.error("SpaCy English model not found. Please install it with: python -m spacy download en_core_web_sm")
        return None

def tokenize_with_nltk(text):
    """Tokenize text using NLTK"""
    tokens = nltk.word_tokenize(text)
    return tokens

def pos_tag_with_nltk(tokens):
    """Perform POS tagging using NLTK"""
    pos_tags = nltk.pos_tag(tokens)
    return pos_tags

def analyze_with_spacy(text, nlp):
    """Analyze text using SpaCy"""
    if nlp is None:
        return None, None, None
    
    doc = nlp(text)
    
    # Extract tokens
    tokens = [token.text for token in doc]
    
    # Extract POS tags
    pos_tags = [(token.text, token.pos_) for token in doc]
    
    # Extract named entities
    entities = [(ent.text, ent.label_) for ent in doc.ents]
    
    return tokens, pos_tags, entities

def get_pos_explanation(tag):
    """Get explanation for POS tags"""
    pos_explanations = {
        'CC': 'Coordinating conjunction',
        'CD': 'Cardinal number',
        'DT': 'Determiner',
        'EX': 'Existential there',
        'FW': 'Foreign word',
        'IN': 'Preposition or subordinating conjunction',
        'JJ': 'Adjective',
        'JJR': 'Adjective, comparative',
        'JJS': 'Adjective, superlative',
        'LS': 'List item marker',
        'MD': 'Modal',
        'NN': 'Noun, singular or mass',
        'NNS': 'Noun, plural',
        'NNP': 'Proper noun, singular',
        'NNPS': 'Proper noun, plural',
        'PDT': 'Predeterminer',
        'POS': 'Possessive ending',
        'PRP': 'Personal pronoun',
        'PRP$': 'Possessive pronoun',
        'RB': 'Adverb',
        'RBR': 'Adverb, comparative',
        'RBS': 'Adverb, superlative',
        'RP': 'Particle',
        'SYM': 'Symbol',
        'TO': 'to',
        'UH': 'Interjection',
        'VB': 'Verb, base form',
        'VBD': 'Verb, past tense',
        'VBG': 'Verb, gerund or present participle',
        'VBN': 'Verb, past participle',
        'VBP': 'Verb, non-3rd person singular present',
        'VBZ': 'Verb, 3rd person singular present',
        'WDT': 'Wh-determiner',
        'WP': 'Wh-pronoun',
        'WP$': 'Possessive wh-pronoun',
        'WRB': 'Wh-adverb'
    }
    return pos_explanations.get(tag, 'Unknown')

def get_ner_explanation(label):
    """Get explanation for NER labels"""
    ner_explanations = {
        'PERSON': 'People, including fictional',
        'NORP': 'Nationalities or religious or political groups',
        'FAC': 'Buildings, airports, highways, bridges, etc.',
        'ORG': 'Companies, agencies, institutions, etc.',
        'GPE': 'Countries, cities, states',
        'LOC': 'Non-GPE locations, mountain ranges, bodies of water',
        'PRODUCT': 'Objects, vehicles, foods, etc. (not services)',
        'EVENT': 'Named hurricanes, battles, wars, sports events, etc.',
        'WORK_OF_ART': 'Titles of books, songs, etc.',
        'LAW': 'Named documents made into laws',
        'LANGUAGE': 'Any named language',
        'DATE': 'Absolute or relative dates or periods',
        'TIME': 'Times smaller than a day',
        'PERCENT': 'Percentage, including "%"',
        'MONEY': 'Monetary values, including unit',
        'QUANTITY': 'Measurements, as of weight or distance',
        'ORDINAL': '"first", "second", etc.',
        'CARDINAL': 'Numerals that do not fall under another type'
    }
    return ner_explanations.get(label, 'Unknown')

def main():
    st.set_page_config(
        page_title="Text Analysis Tool",
        page_icon="üìù",
        layout="wide"
    )
    
    st.title("üìù Text Analysis Tool")
    st.markdown("Ph√¢n t√≠ch vƒÉn b·∫£n v·ªõi Tokenization, POS Tagging v√† Named Entity Recognition")
    
    # Load SpaCy model
    nlp = load_spacy_model()
    
    # Sidebar for input
    st.sidebar.header("Nh·∫≠p vƒÉn b·∫£n")
    
    # Text input
    text_input = st.sidebar.text_area(
        "Nh·∫≠p vƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch:",
        value="Apple Inc. was founded by Steve Jobs in California on April 1, 1976. The company is now worth over $3 trillion.",
        height=200
    )
    
    # Analysis options
    st.sidebar.header("T√πy ch·ªçn ph√¢n t√≠ch")
    use_spacy = st.sidebar.checkbox("S·ª≠ d·ª•ng SpaCy (khuy·∫øn ngh·ªã)", value=True)
    use_nltk = st.sidebar.checkbox("S·ª≠ d·ª•ng NLTK", value=True)
    
    if st.sidebar.button("Ph√¢n t√≠ch vƒÉn b·∫£n", type="primary"):
        if not text_input.strip():
            st.error("Vui l√≤ng nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ ph√¢n t√≠ch!")
            return
        
        # Main content area
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.header("üìä K·∫øt qu·∫£ ph√¢n t√≠ch")
            
            # Tokenization
            if use_nltk:
                st.subheader("üî§ Tokenization (NLTK)")
                nltk_tokens = tokenize_with_nltk(text_input)
                st.write(f"**S·ªë l∆∞·ª£ng tokens:** {len(nltk_tokens)}")
                st.write("**Tokens:**")
                st.write(nltk_tokens)
            
            if use_spacy and nlp:
                st.subheader("üî§ Tokenization (SpaCy)")
                spacy_tokens, _, _ = analyze_with_spacy(text_input, nlp)
                st.write(f"**S·ªë l∆∞·ª£ng tokens:** {len(spacy_tokens)}")
                st.write("**Tokens:**")
                st.write(spacy_tokens)
        
        with col2:
            # POS Tagging
            if use_nltk:
                st.subheader("üè∑Ô∏è POS Tagging (NLTK)")
                nltk_tokens = tokenize_with_nltk(text_input)
                nltk_pos = pos_tag_with_nltk(nltk_tokens)
                
                # Create DataFrame for better display
                pos_df = pd.DataFrame(nltk_pos, columns=['Token', 'POS Tag'])
                pos_df['Explanation'] = pos_df['POS Tag'].apply(get_pos_explanation)
                st.dataframe(pos_df, use_container_width=True)
            
            if use_spacy and nlp:
                st.subheader("üè∑Ô∏è POS Tagging (SpaCy)")
                _, spacy_pos, _ = analyze_with_spacy(text_input, nlp)
                
                # Create DataFrame for better display
                spacy_pos_df = pd.DataFrame(spacy_pos, columns=['Token', 'POS Tag'])
                st.dataframe(spacy_pos_df, use_container_width=True)
        
        # Named Entity Recognition
        st.header("üéØ Named Entity Recognition")
        
        if use_spacy and nlp:
            _, _, entities = analyze_with_spacy(text_input, nlp)
            
            if entities:
                st.subheader("SpaCy NER Results")
                
                # Create DataFrame for entities
                entity_df = pd.DataFrame(entities, columns=['Entity', 'Label'])
                entity_df['Explanation'] = entity_df['Label'].apply(get_ner_explanation)
                
                # Display entities
                st.dataframe(entity_df, use_container_width=True)
                
                # Highlight entities in text
                st.subheader("VƒÉn b·∫£n v·ªõi entities ƒë∆∞·ª£c highlight")
                highlighted_text = text_input
                for entity, label in entities:
                    highlighted_text = highlighted_text.replace(
                        entity, 
                        f"**{entity}** ({label})"
                    )
                st.markdown(highlighted_text)
                
                # Entity statistics
                st.subheader("üìà Th·ªëng k√™ Entities")
                entity_counts = Counter([label for _, label in entities])
                
                if entity_counts:
                    # Create pie chart
                    fig = px.pie(
                        values=list(entity_counts.values()),
                        names=list(entity_counts.keys()),
                        title="Ph√¢n b·ªë c√°c lo·∫°i Entity"
                    )
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("Kh√¥ng t√¨m th·∫•y entities n√†o trong vƒÉn b·∫£n.")
        
        # Text statistics
        st.header("üìä Th·ªëng k√™ vƒÉn b·∫£n")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("S·ªë k√Ω t·ª±", len(text_input))
        
        with col2:
            words = text_input.split()
            st.metric("S·ªë t·ª´", len(words))
        
        with col3:
            sentences = text_input.split('.')
            st.metric("S·ªë c√¢u", len([s for s in sentences if s.strip()]))
        
        with col4:
            if use_spacy and nlp:
                _, _, entities = analyze_with_spacy(text_input, nlp)
                st.metric("S·ªë entities", len(entities))
            else:
                st.metric("S·ªë entities", "N/A")
    
    # Footer
    st.markdown("---")
    st.markdown("**Text Analysis Tool** - S·ª≠ d·ª•ng NLTK v√† SpaCy ƒë·ªÉ ph√¢n t√≠ch vƒÉn b·∫£n")
    
    # Instructions
    with st.expander("üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"):
        st.markdown("""
        ### C√°ch s·ª≠ d·ª•ng:
        1. **Nh·∫≠p vƒÉn b·∫£n** v√†o √¥ text area b√™n tr√°i
        2. **Ch·ªçn ph∆∞∆°ng ph√°p ph√¢n t√≠ch** (NLTK ho·∫∑c SpaCy)
        3. **Nh·∫•n n√∫t "Ph√¢n t√≠ch vƒÉn b·∫£n"**
        
        ### C√°c t√≠nh nƒÉng:
        - **Tokenization**: T√°ch vƒÉn b·∫£n th√†nh c√°c tokens
        - **POS Tagging**: G·∫Øn nh√£n t·ª´ lo·∫°i cho m·ªói token
        - **Named Entity Recognition**: Nh·∫≠n d·∫°ng c√°c th·ª±c th·ªÉ c√≥ t√™n
        
        ### C√†i ƒë·∫∑t:
        ```bash
        pip install -r requirements.txt
        python -m spacy download en_core_web_sm
        ```
        
        ### Ch·∫°y ·ª©ng d·ª•ng:
        ```bash
        streamlit run app.py
        ```
        """)

if __name__ == "__main__":
    main()
